{"cells": [{"cell_type": "markdown", "id": "1f04f7c6-9e82-4e7a-928e-d14b08f939e9", "metadata": {}, "source": "**Key COnsideration for Dataproc Cluster"}, {"cell_type": "code", "execution_count": 2, "id": "1a963abd-d54f-416b-9fa6-42e6b8c0ebd3", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/12/26 01:09:47 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('Olist Ecommernce Optimization').getOrCreate()\n"}, {"cell_type": "code", "execution_count": 4, "id": "2c6168fe-c288-4c69-a173-89ac70ef9dd3", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/12/26 01:11:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('Olist Ecommernce Optimization')\\\n.config('spark.executor.memory','2g') \\\n.config('spark.executor.cores','2') \\\n.config('spark.executor.instances', '2') \\\n.config('spark.driver.memory', '2g')\\\n.config('spark.driver.maxResultsSize','2g') \\\n.config('spark.sql.shuffle.partitions', '64')\\\n.config('spark.default.parallelism', '64') \\\n.config('spark.sql.adaptive.enabled', 'true') \\\n.config('spark.sql.adaptive.coalescePartition.enabled', 'true') \\\n.config('spark.sql.autoBroadcastJoinThreshold',20*1024*1024) \\\n.config('spark.sql.files.maxPartitionBytes', '64MB') \\\n.config('spark.sql.files.openCOstInBytes', '2MB') \\\n.config('spark.memory.fraction', 0.8) \\\n.config('spark.memory.storageFraction', 0.2) \\\n.getOrCreate()\n\n\n\n\n"}, {"cell_type": "code", "execution_count": 5, "id": "bb1ac869-c421-46c1-aa10-a780f69b3709", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import *\nfrom pyspark.sql.functions import *"}, {"cell_type": "code", "execution_count": 6, "id": "65ec3fef-fbd6-4ced-bb0b-b9df619f40dd", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "path = '/data/'\ngeolocation = spark.read.csv(path+'olist_geolocation_dataset.csv',header=True,inferSchema = True)\norder_items = spark.read.csv(path+'olist_order_items_dataset.csv',header=True,inferSchema = True)\npayments = spark.read.csv(path+'olist_order_payments_dataset.csv',header=True,inferSchema = True)\nreviews = spark.read.csv(path+'olist_order_reviews_dataset.csv',header=True,inferSchema = True)\norders = spark.read.csv(path+'olist_orders_dataset.csv',header=True,inferSchema = True)\nproducts = spark.read.csv(path+'olist_products_dataset.csv',header=True,inferSchema = True)\nseller = spark.read.csv(path+'olist_sellers_dataset.csv',header=True,inferSchema = True)\ncustomer = spark.read.csv(path+'olist_customers_dataset.csv',header=True,inferSchema = True)"}, {"cell_type": "markdown", "id": "112f4d12-0c3e-42db-a12b-73d717c0f31e", "metadata": {}, "source": "**Optimize Join Strategies"}, {"cell_type": "code", "execution_count": 8, "id": "7845678c-8f8d-498f-802b-8f18ce98f14e", "metadata": {"tags": []}, "outputs": [], "source": "#Broadcast\n\n\n\nbroadcast_customer = broadcast(customer)\noptimized_broadcast_join = all_dataframe.join(broadcast_customer,'customer_id')\n\n"}, {"cell_type": "code", "execution_count": 9, "id": "acd82938-da06-4ea8-bdcd-28c17c7f4783", "metadata": {"tags": []}, "outputs": [], "source": "#Sort And Merge Join\n\nsorted_customer = customer.sortWithinPartitions('customer_id')\nsorted_orders = all_dataframe.sortWithinPartitions('customer_id')\n\n\noptimized_merge_all_dataframe = sorted_orders.join(sorted_customer,'customer_id')"}, {"cell_type": "code", "execution_count": null, "id": "fe7aa753-aa76-420f-9fde-2f3d88606fd8", "metadata": {}, "outputs": [], "source": "#Bucket Join\n\nbucketed_customer = customer.repartition(10, 'customer_id')\nbucketed_order = all_dataframe.repartition(10, 'customer_id')\n\nbucketed_all_dataframe = bucketed_order.joing(bucketed_customer,'customer_id')"}, {"cell_type": "code", "execution_count": 10, "id": "58ad847b-c482-42dd-ba07-2987e84c3a8b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "olist_full = spark.read.parquet('/data/processed')"}, {"cell_type": "code", "execution_count": 11, "id": "76c59ccb-fedc-4005-aecb-0c47dd553b61", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- customer_id: string (nullable = true)\n |-- seller_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- order_id: string (nullable = true)\n |-- order_item_id: integer (nullable = true)\n |-- shipping_limit_date: timestamp (nullable = true)\n |-- price: double (nullable = true)\n |-- freight_value: double (nullable = true)\n |-- order_status: string (nullable = true)\n |-- order_purchase_timestamp: timestamp (nullable = true)\n |-- order_approved_at: timestamp (nullable = true)\n |-- order_delivered_carrier_date: timestamp (nullable = true)\n |-- order_delivered_customer_date: timestamp (nullable = true)\n |-- order_estimated_delivery_date: timestamp (nullable = true)\n |-- payment_sequential: integer (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- payment_installments: integer (nullable = true)\n |-- payment_value: double (nullable = true)\n |-- review_id: string (nullable = true)\n |-- review_score: string (nullable = true)\n |-- review_comment_title: string (nullable = true)\n |-- review_comment_message: string (nullable = true)\n |-- review_creation_date: string (nullable = true)\n |-- review_answer_timestamp: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n |-- product_category_name: string (nullable = true)\n |-- product_name_lenght: integer (nullable = true)\n |-- product_description_lenght: integer (nullable = true)\n |-- product_photos_qty: integer (nullable = true)\n |-- product_weight_g: integer (nullable = true)\n |-- product_length_cm: integer (nullable = true)\n |-- product_height_cm: integer (nullable = true)\n |-- product_width_cm: integer (nullable = true)\n |-- seller_zip_code_prefix: integer (nullable = true)\n |-- seller_city: string (nullable = true)\n |-- seller_state: string (nullable = true)\n |-- geolocation_zip_code_prefix: integer (nullable = true)\n |-- geolocation_lat: double (nullable = true)\n |-- geolocation_lng: double (nullable = true)\n |-- geolocation_city: string (nullable = true)\n |-- geolocation_state: string (nullable = true)\n |-- customer_segment: string (nullable = true)\n |-- order_day_type: string (nullable = true)\n |-- hour_of_day: integer (nullable = true)\n\n"}], "source": "olist_full.printSchema()"}, {"cell_type": "code", "execution_count": null, "id": "896c5e83-fe6a-44f8-973e-ca35f597a1e7", "metadata": {}, "outputs": [], "source": "#Caching"}, {"cell_type": "code", "execution_count": null, "id": "b975bd78-5c68-4f97-8c2b-4aaacedb8ec8", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}